---
title: "EVALUATING  CORE INFLATION MEASURES"
author: "Yiyi"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
  header-includes:
  - \usepackage{placeins}
  - \usepackage{multirow}
  - \usepackage{multicolumn}
  - \usepackage{caption}
  - \usepackage[absolute,overlay]{textpos}
  - \usepackage{float}
  - \usepackage{graphicx}
  - \usepackage{booktabs}
  html_document:
    toc: yes
    df_print: paged
  word_document: default
  bookdown::pdf_document2:
    toc: yes
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r rm, include=FALSE}
 rm(list = ls())
Sys.setlocale("LC_TIME", "English")
```

```{r Library, include=FALSE}
#Packages
library(readxl)
library(data.table)
library(lubridate)#extract cpi time to newdata(furniture48)
library(tidyverse) 
library(broom)
library(stargazer)
library(knitr)
library(officer)
library(flextable)
library(magrittr)
library(dplyr)
library(moments)
library(Inflation)
library(ggplot2)
library(zoo)
library(xts)
library(hydroTSM)
library(openair)
library(tibble)
library(miscTools)
library(priceR)
library(Metrics)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(kableExtra)
library(gridExtra)
library(egg)
library(grid)
library(cowplot)
library(spatstat)#shift有重复
library(SciViews)
library(sos)
```

```{r language,message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
Sys.setlocale("LC_TIME","English")
```

# Sticky price measures

We examine the frequency of price changes for 570 categories of goods and services covering about 66.4% of consumer spending based on "Dixon and Tian items frequency data". Then, I looked up the monthly CPI index and weights data for these 570 items based on their ID one by one for the years 2005 to 2021. This is used to construct CORE inflation measures of sticky and flexible CPI.

Dixon and Tian items frequency data provides the frequency (expressed as a %) of prices changing per month for 570 items that were contained in the VML data set for the whole period January 1996 to December 2007. Column A is the COICOP item id. The frequency is in Colmn D. The "clear weight" in column C is the actual CPI weight (total across all categories sum to 1000). The rebase weight in column are made to add up to 1000 (their total share in CPI is 664). Let $\lambda=$ the monthly frequency of price changes. Mo = the mean duration between price changes implied by $[=-1 / \ln (1-\lambda)]$. If prices can change at any moment, not just at the monthly interval, the instantaneous probability of a price change is $-\operatorname{In}(1-\lambda)$ and the mean time between price changes $-1 / \ln (1-\lambda)$ months. We used this formula to calculate the Mo. column from the Freq. column in Table 1. If prices instead change at most once per month, then the mean duration is simply $1 / \lambda$, about half a month longer.

The monthly frequency of price changes averages 21.78278%. The weighted median is 17.9%.

```{r sticky price, include=FALSE}
#从Dixon and tian的数据里， 把frequency划分为sticky 和 flexible
#再根据名字找相应的年份的cpi 和weight 构建stickey price把

Dixon_tian<-read_excel("Dixon_and_Tian_570_item_Freq yiyi (version 1).xlsx","Sheet2")
#data.frame
Dixon_tian<-data.frame(Dixon_tian)
#all numerical col 3 4 5

Dixon_tian[,3:7]<-sapply(Dixon_tian[,3:7],as.numeric)
Dixon_tian<-Dixon_tian[-570,]
colnames(Dixon_tian)[7]<-c("Accumulative weight")
#寻找col 4小于4.3的行
sticky_row<-which(Dixon_tian$frequency<4.3)
#很明显，这里不能用4.3做分界
#For the median category the time between price change averages 4.3 months.
#中位数？平均数？cpi权重的中位数？
#Median by CPI weight
#location_median_cpiweight<-which(Dixon_tian$...7==median(Dixon_tian$...7))
#Dixon_tian[location_median_cpiweight,]


#Dixon_tian[location_Means,]

#weighted media
#matrixStats::weightedMedian(Dixon_tian$rebase.weight,Dixon_tian$frequency)

#For the median category the time between price change averages 4.3 months.
#中位数的平均数是20， 20以下就是sticky
sum(Dixon_tian$clear.weight)
tail(Dixon_tian)
sum(Dixon_tian$rebase.weight)
#Means (weighted and unweighted)

mean(Dixon_tian$frequency)#21.78278 正确答案21 573.53
mean(Dixon_tian$`Accumulative weight`)#525.5079


weighted.mean(Dixon_tian$frequency,Dixon_tian$rebase.weight)#22.31121 607.82

weighted.mean(Dixon_tian$frequency,Dixon_tian$`Accumulative weight`)
#weighted Median in list.
#17.9
weighted.median(Dixon_tian$frequency,Dixon_tian$rebase.weight)#17.9 496.34

weighted.median(Dixon_tian$frequency,Dixon_tian$clear.weight)#17.9

median(Dixon_tian$frequency)#20
#location_median<-which(Dixon_tian$frequency==median(Dixon_tian$frequency))
#Dixon_tian[location_median,]

#除了mean不对，别的都能和excel表中的黄色对应的上
#文章里用的是weight median
#17.9介于18和17.8之间
#直接按照18作为分界线
#location_median<-which(Dixon_tian$frequency==weighted.median(Dixon_tian$frequency,Dixon_tian$rebase.weight))
#Dixon_tian[location_median,]
kbl(Dixon_tian,caption = "The Frequency of Price Changes by Category",col.names=c("item_id
","$item_des$","$clear weight$","frequency","$rebase weight$","$Mo$","Accumulative weight" ),escape = FALSE) %>%
  kable_classic() %>%
  kable_styling(latex_options = c("striped", "hold_position"))

#取消spatstat package 还原shift funciton
unloadNamespace("spatstat")

```

```{r include=FALSE}

#寻找col 4小于17.9的行
sticky_row<-which(Dixon_tian$frequency<17.9)
#一共多少个/284
length(sticky_row)
#用他们的id在 item completely里找对应的cpi和weight把
#读取数据
#马勒戈壁读取名字的时候 会把colname改名字
#所以列名不能实名制
item_cpi<-read_excel("item_indices_complete.xlsx","Sheet2",col_names = FALSE)
#第一行和第二列没啥东西 都删了
item_cpi<-item_cpi[-2,-2]
#除了前第一列以外别的列转化为numerical
item_cpi<-data.frame(item_cpi)
#
item_cpi[2:nrow(item_cpi), 2:ncol(item_cpi)] <-as.numeric(unlist(item_cpi[2:nrow(item_cpi), 2:ncol(item_cpi)]))
#

#
#只在cpi里数据里找到了个290个， 但是应该有的sticky 是284个,。
df<-Dixon_tian[sticky_row,1]#284
df2<-item_cpi[1,]#1144
#common_id<-intersect(df,df2)#282
#setdiff(df,common_id)
#410103 410101 两个狗崽中 在item cpi里找不到 操你妈的
location_in_cpi<-which(item_cpi[1,] %in% Dixon_tian[sticky_row,1]==TRUE)
new<-item_cpi[,location_in_cpi]
setdiff(df,new[1,])
#   是有共同用id的问题
# 例如212917就有两个


```

```{r eval=FALSE, include=FALSE}
Dixon_tian<-read_excel("Dixon_and_Tian_570_item_Freq yiyi.xlsx","Data")

Dixon_tian<-data.frame(Dixon_tian)

Dixon_tian[,3:5]<-sapply(Dixon_tian[,3:5],as.numeric)

Dixon_tian<-Dixon_tian[-571,]
Dixon_tian[is.na(Dixon_tian)]<-0

tail(Dixon_tian)

sum(Dixon_tian$rebase.weight)
sum(Dixon_tian$clear.weight)

weighted.mean(Dixon_tian$frequency,Dixon_tian$rebase.weight)#17.9

weighted.median(Dixon_tian$frequency,Dixon_tian$rebase.weight)#22.31

mean(Dixon_tian$frequency)#21.74456
```

# Criteria for evaluation : forecasting future inflation

This work uses Cogley's model to test the forecasting ability of core inflation rate, and it also compares the forecasting ability of various core inflation measures, including Excluding food and energy and Trimmed mean  Cogley's model is based on Bryan and Cecchetti's definition of core inflation: "Core inflation is changes in the price level that are expected to persist over a long period of time."

According to Bryan and Cecchetti's definition, a valid core inflation is one that is "pure" after removing temporary factors from measured real inflation. On this basis, Cogley developed the following model to evaluate the predictive power of core inflation:

```{r latex, include=FALSE}
#想在r markdown里输入latex公式居中 首先需要首位$$\begin{} \end{}$$
#html公式后面是没有标号的，pdf有
#这个 公式模型 我自己用ols也能做啊？
#就做一个df，有三列数据，第一列x_t+12,第二列x_t,第三列core
#日期的问题
#
```

$$\pi_{t+h}-\pi_{t}=\alpha_{h}+\beta_{h}\left(\pi_{t}-\pi_{t}^{c}\right)+u_{t+h}$$

Here, x represents the headline inflation rate and core x represents some core inflation indicator, both year-on-year data. Parameter h is N (month) ahead. For sufficiently large H, the core deviation, $\left(\pi_{t}-\pi_{t}^{c}\right)$, should be inversely related to subsequent changes in inflation, $\pi_{t+h}-\pi_{t}$. Moreover, in order for the candidate to satisfy equation (1), the coefficients in the regression, should satisfy $\alpha=0$ and $\beta = -1$.

Of importance to the forecasting model is the estimated coefficient of $\beta$, which indicates whether core inflation has sufficiently purified the transitory component. Because if the absolute value of the estimated coefficient is equal to 1, it indicates that the model is a random walk process, and the components removed from the core inflation do not contain any information that predicts future overall inflation. If $\beta=-1$, the forecasting capacity for core inflation is the best . This proves that core inflation has fully captured the trend components of overall inflation and has a complete forecasting ability for future inflation.

1.  If the $|\beta|<1$, it indicates that subsequent changes in inflation are overestimated;

2.  If the $|\beta|>1$, it shows that underestimation of the current temporary movement in headline inflation.

Therefore, the closer the absolute value of the estimated regression coefficient $\beta$ is to 1, the better the predictive power of core inflation is. In addition, the root mean square error RMSE $=\sqrt{\frac{1}{\mathrm{~T}} \sum_{\mathrm{t}=1}^{\mathrm{T}}\left(\pi_{\mathrm{t}}-\hat\pi_{\mathrm{t}}\right)^{2}}$obtained by Cogley regression represents the deviation between the predicted value and the actual value. $\hat\pi_{\mathrm{t}}$ is the forecast value of the inflation rate. The smaller the RMSE, the more accurate the forecast. and the better the forecast of core inflation.

```{r V1 excluding, include=FALSE}
#首先导入数据
#05.1对应的是x+12是06.1
#那尾部又不够了， 重新搞一份全的cpi重新提取把
core_headline<-read_excel("V2 core excluding food and energy.xlsx","Comparision")
#读取全部的cpi数据
headline_df<-read_excel("UK ALL year CPI.xls")
#提取2006JAN -2020 DEC的数据作为x+12
#开始结束的位置
start_poisition<-which(headline_df$Title=="2006 JAN")
end_poisition<-which(headline_df$Title=="2020 DEC")
#把开始结束的之间的内容提取到主df里
core_headline[,7]<-headline_df[start_poisition:end_poisition,2]
#命名新的列
colnames(core_headline)[7]<-c("x+12")
#把几个数据都改为numerical
core_headline[, 4:7] <- sapply(core_headline[,4:7], as.numeric)
core_headline<-data.frame(core_headline)
#生成x_core-x -> difference
core_headline$difference<- core_headline$CPI.ANNUAL.RATE.00..ALL.ITEMS.2015.100 - core_headline$Core.inflation.excluding.food.and.energy.
#left difference
colnames(core_headline)<-c("titlle","time","origin","core","CPI","approx","x+12","difference")
core_headline$left_difference<-core_headline$`x+12`- core_headline$CPI
#core_jeadline$difference 改名字为beta方便输出
colnames(core_headline)[8]<-c("beta")
#regression
regression<-lm(core_headline$left_difference~ beta,data = core_headline)

```

```{r 6 12 food,include=FALSE}
#6 months ahead
start_poisition_6<-which(headline_df$Title=="2005 JUL")
end_poisition_6<-which(headline_df$Title=="2020 JUN")
#把开始结束的之间的内容提取到主df里
core_headline$"6 month ahead"<-headline_df[start_poisition_6:end_poisition_6,2]
#9 months 
start_poisition_9<-which(headline_df$Title=="2005 OCT")
end_poisition_9<-which(headline_df$Title=="2020 SEP")
#把开始结束的之间的内容提取到主df里
core_headline$"9 month ahead"<-headline_df[start_poisition_9:end_poisition_9,2]
core_headline[, 10:11] <- sapply(unlist(core_headline[,10:11]), as.numeric)
#6 month diff
core_headline$"6 months diff"<-core_headline$`6 month ahead`-core_headline$CPI
#9month diff
core_headline$"9 months diff"<-core_headline$`9 month ahead`- core_headline$CPI
#regression 6 head
regression_6<-lm(core_headline$`6 months diff`~ beta,data = core_headline)
#regression 9 head
regression_9<-lm(core_headline$`9 months diff`~ beta,data = core_headline)
```

```{r  trimmed, include=FALSE}
#Trend
#我把trend的也向前做了12期，其实是错误的
#我唯一要做的就是ukcpi向前推12期
#如果我想做05.1-19.12的， 那对应的数据范围是05.2-20.12
#尝试建立连续12个月的预测
#%%
#95.1-21.10
TM<-read_excel("Trimmed mean.xlsx")
TM<-as.data.table(TM)
#我的idea是：
#1.首先生成12列lead，每一行第一个数都是上一列的第二行
#2. 这样后面十二列都减去第一列就是x12— x。也就是等式左边的数据了
#lead 超前12个月的预测


#TM[, paste0("lead", 1L:3L) := shift(`CPI-trim (5%)`, 1L:3L, type = "lead"), by = groups]
TM <- TM[, unlist(lapply(.SD, shift,type = "lead", n = 0:12), recursive = FALSE),.SDcol=2]
#
TM<-data.frame(TM)
#这个式子不在data。frame里运行不了。
TM[2:ncol(TM)] <- TM[2:ncol(TM)]-TM[,1]
#这代码的意思是： 对2：13列的数据减去他们自己的lag1数据
#sad<-TM %>% mutate(across(2:13, ~. - lag(.)) )
#date
date_t = seq(from = as.Date("1995-01-01"), to = as.Date("2021-10-01"),
           by = "month")#生成日期
TM<-add_column(TM,date_t,.before = 1)
#挑选05.1 ： 19.12
TM_05<-TM[TM$date_t>="2005-01-01" & TM$date_t<="2019-12-01",]


```

# Results

From the above discussion, I used my own data to re-simulate the values of the parameters.The results please see Table \@ref(tab:summary), figure \@ref(fig:overall).

```{r  forcast main code,include=FALSE}

#读取cpi 数据
#1989 JAn 开始
#2021 OCT 结束
start_poisition_all<-which(headline_df$Title=="1989 JAN")
end_poisition_all<-which(headline_df$Title=="2021 OCT")
CPI_alll<-headline_df[start_poisition_all:end_poisition_all,2]
#转化数据类型
CPI_alll[,1]<-as.numeric(unlist(CPI_alll[,1]))
#
CPI_alll<-as.data.table(CPI_alll)
#lead 超前12个月的预测
library(data.table) 

CPI_alll <- CPI_alll[, unlist(lapply(.SD, shift,type = "lead", n = 0:12), recursive = FALSE),.SDcol=1]
#
CPI_alll<-data.frame(CPI_alll)
#这个式子不在data。frame里运行不了。
#2:13列 x+1 - x+12 都 减去 x
CPI_alll[2:ncol(CPI_alll)] <- CPI_alll[2:ncol(CPI_alll)]-CPI_alll[,1]
#建立时间序列
#date
date_all = seq(from = as.Date("1989-01-01"), to = as.Date("2021-10-01"),
           by = "month")#生成日期
CPI_alll<-add_column(CPI_alll,date_all,.before = 1)
#我需要05.1-19.12
CPI519<-CPI_alll[CPI_alll$date_all>="2005-01-01" & CPI_alll$date_all<="2019-12-01",]
#列命名
# 1.2.3.... months diff?
#
colnames(CPI519)[2]<-c("CPI")
colnames(CPI519)[3:14]<- paste(1:12,"months difference ",sep=" ")
#把05-19的各种core 导入cpi519 并且 core difference with CPI
 #excluding food and energy
CPI519$excluding_food_and_energy<-CPI519$CPI - core_headline$core
#trimmed
CPI519$Trimmed_mean<-CPI519$CPI -TM_05$CPI.trim..5..1
#regression
#每个core 对应12列
# #excluding food and energy
res_excluding<-lapply(3:14, function(x) lm(CPI519[,x]~ CPI519$excluding_food_and_energy))
RMSE_food<-unlist(lapply(1:12, function(x) sqrt(mean(res_excluding[[x]]$residuals^2)))
)
cof_food_alpha<-unlist(lapply(1:12, function(x) res_excluding[[x]]$coefficients[1]))
cof_food_beta<-unlist(lapply(1:12, function(x) res_excluding[[x]]$coefficients[2]))

#Trimmed mean
res_trimmed<-lapply(3:14, function(x) lm(CPI519[,x]~ CPI519$Trimmed_mean))
RMSE_trimmed<-unlist(lapply(1:12, function(x) sqrt(mean(res_trimmed[[x]]$residuals^2)))
)
cof_trimmed_alpha<-unlist(lapply(1:12, function(x) res_trimmed[[x]]$coefficients[1]))
cof_trimmed_beta<-unlist(lapply(1:12, function(x) res_trimmed[[x]]$coefficients[2]))

#
dt<-cbind(RMSE_food,cof_food_alpha,cof_food_beta)
rownames(dt)<-paste(1:12,"months ahead")
colnames(dt)<-c("RMSE","$\alpha$","$\beta$" )
dt %>%
  kbl() %>%
  kable_paper("hover", full_width = F)

```

```{r summary, echo=FALSE}
together<-cbind(RMSE_food,cof_food_alpha,cof_food_beta,RMSE_trimmed,cof_trimmed_alpha,cof_trimmed_beta)
rownames(together)<-paste(1:12,"months ahead")
colnames(together)<-c("RMSE","$\\alpha$","$\\beta$","RMSE","$\\alpha$","$\\beta$" )

kbl(together,caption = "Headline CPI Forecast Accuracy: Root Mean Squared Errors and Beta",col.names=c("RMSE","$\\alpha$","$\\beta$","RMSE","$\\alpha$","$\\beta$" ),escape = FALSE) %>%
  kable_classic() %>%
  kable_styling(latex_options = c("striped", "hold_position")) %>%
  add_header_above(c(" " , "Excluding Food and Energy" = 3, "Trimmed Mean" = 3)) %>%
  add_header_above(c(" ", "Core Inflation " = 6))


```

```{r plot RMSE, echo=FALSE}
together<-data.table(together)
colnames(together)<-paste0("c",1:6)
#ggplot
together$idu <- as.numeric(row.names(together))



```

```{r RMSE, echo=FALSE, fig.cap="Cogley Regression RMSE", fig.topcaption=TRUE, message=FALSE, warning=FALSE,results='asis'}
p<-ggplot(data=together, aes(x=idu))+
 geom_line(aes(y =c1, color="Ex F&E")) +
   geom_line(aes(y = c2, color="Trimmed Mean ")) +
labs(x="Forecast Horizon (Months)",y="RMSE")
#p + theme(legend.title = element_blank()) 

```

```{r beta,  echo=FALSE, fig.cap="Cogley Regression Beta estimates", fig.topcaption=TRUE, message=FALSE, warning=FALSE}
#beta
q<-ggplot(data=together, aes(x=idu))+
 geom_line(aes(y =c3, color="Ex F&E")) +
   geom_line(aes(y = c6, color="Trimmed Mean ")) +
labs(x="Forecast Horizon (Months)",y="Beta")
#q + theme(legend.title = element_blank())

```

```{r cpi trend, echo=FALSE}
trend05<-cbind(CPI519$date_all,CPI519$CPI,TM_05$CPI.trim..5..1,core_headline$core)
CPI519$TM<-TM_05$CPI.trim..5..1
CPI519$EXFD<-core_headline$core
#ggplot
nt<-ts(CPI519$date,start = c(2005,1),frequency = 12 )

```

```{r coreheadlinecpi, echo=FALSE, fig.cap="Core CPI and Headline CPI.", fig.topcaption=TRUE, message=FALSE, warning=FALSE}
w<-ggplot(data=CPI519, aes(x=time(nt)))+
 geom_line(aes(y = TM, color="Trimmed Mean")) +
   geom_line(aes(y = EXFD, color="Ex F&E")) +
     geom_line(aes(y = CPI, color="CPI Inflation")) +
labs(x="Time",y="Inflation")
#w + theme(legend.title = element_blank()) 
```

```{r overall, fig.cap= "overall", echo=FALSE,fig.topcaption=TRUE, message=FALSE, warning=FALSE}
grid.arrange(arrangeGrob(p, top = 'Cogley Regression RMSE') , arrangeGrob(q, top = 'Cogley Regression Beta estimates'),arrangeGrob(w, top = 'Core CPI and Headline CPI'), nrow=3)
```

\newpage

# Conclusions

As expected, all Cogley regressions of the core inflation rate with $\beta$ estimates are all negative. The beta keeps falling as the number of forecast periods rises; The forecast RMSE for core inflation rates increases as the number of forecast periods increases continuously. This suggests that the longer the forecast period, the more inaccurate the forecast. It can be seen that the forecast ability of Excluding Food and Energy is not good as Trimmed Mean. Excluding Food and Energy coefficient estimates of the Cogley regression deviate the furthest from - 1 within 10 months forecast horizon and the root mean squared error (RMSE) of the predictions is the largest in all prediction periods. The interesting point is that when forecast horizon exceeds 10 months, the coefficient estimates of the Trimmed mean deviate from -1 becoming further away than EX F&E.

```{r eval=FALSE, include=FALSE}
### 6 months ahead
#RMSE 6
RSS <- c(crossprod(regression_6$residuals))
MSE <- RSS / length(regression_6$residuals)
sig2 <- RSS / regression_6$df.residual

sqrt(mean(regression_6$residuals^2))


### 9 months ahead

#RMSE 9
RSS <- c(crossprod(regression_9$residuals))
MSE <- RSS / length(regression_9$residuals)
sig2 <- RSS / regression_9$df.residual

sqrt(mean(regression_9$residuals^2))


### 12 months ahead


#RMSE 12
RSS <- c(crossprod(regression$residuals))
MSE <- RSS / length(regression$residuals)
sig2 <- RSS / regression$df.residual

sqrt(mean(regression$residuals^2))


## Coefficients

### 6 months ahead

summary(regression_6)

### 9 months ahead

summary(regression_9)


### 12 months ahead

summary(regression)
```
